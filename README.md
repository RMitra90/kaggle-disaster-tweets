# Real or Not? NLP with Disaster Tweets

The challenge was a [Kaggle competition](https://www.kaggle.com/c/nlp-getting-started). 

My kernel is an adaptation of the amazing work done by [@gunesevitan](https://www.kaggle.com/gunesevitan). Check out his notebook here - [NLP with Disaster Tweets - EDA, Cleaning and BERT](https://www.kaggle.com/gunesevitan/nlp-with-disaster-tweets-eda-cleaning-and-bert). I followed the EDA and text cleaning process almost exactly as done in the cited notebook and I have not included EDA steps in my kernel. 

When the kernel was submitted to Kaggle, it was ranked 295 out of 1484 teams (Top 20%) in the leaderboard. 

Here is a [link](https://www.kaggle.com/rmitra/disaster-tweets-classification-using-bert) to my notebook on Kaggle.
